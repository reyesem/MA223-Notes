# Study Design {#ANOVAdata}

Chapter \@ref(Data) discussed the impact that the design of the study has on interpreting the results.  Recall that the goal of any statistical analysis is to use the sample to say something about the underlying population.  Observational studies are subject to confounding.  In order to use the available data in order to make causal statements that apply within the population, we need to address the confounding.  There are two ways of doing this:

  1. Conduct a controlled experiment.  While we do not limit our discussion to controlled experiments in this unit, our discussion will emphasize the elements of a well designed experiment.  
  2. Use observational data and account for confounders.  This can be addressed through regression modeling as discussed in Chapter \@ref(Regextensions).
  
As discussed in Chapter \@ref(Data), controlled experiments balance the groups being compared relative to the potential confounders.  As a result, such studies permit causal conclusions to be drawn.


## Aspects of a Well Designed Experiment
Generally speaking, there are three components to a well-designed study: replication, randomization, and comparative groups.

As we have stated repeatedly, variability is inherit in any process.  We know there is variability in the population; not every subject will respond exactly the same to each treatment.  Therefore, our questions do not seek to answer statements about individuals but about general trends in the population.  In order to establish these general trends, we must allow that subject-to-subject variability be present within the study itself.  This is accomplished through __replication__, obtaining data on multiple subjects from each group.  Each subject's response would be expected to be similar, with variability within the group due to the inherit variability in the data-generating process.

```{definition, label=defn-replication, name="Replication"}
Taking measurements on different subjects, for which you expect the results to be similar.  That is, any variability is due to nautral variability within the population.
```

When we talk about gathering "more data," we typically mean obtaining a larger number of replicates.  Ideally, replicates will be obtained through _random selection_ from the underlying population to ensure they are representative.  The subjects are then _randomly allocated_ to a particular level of the factor under study (randomly allocated to a group).  This random allocation breaks the link between the factor and any potential confounders, allowing for causal interpretations.  However, if a link exists between the factor and the response, that is preserved.  These are the two aspects of __randomization__.

```{definition, label=defn-randomization, name="Randomization"}
Refers to the random _selection_ of subjects which minimizes bias and random _allocation_ of subjects which permits causal interpretation.
```

```{block2, type="rmdtip"}
While students can typically describe random selection vs. random allocation, they often confuse their purpose.  Random selection is to ensure the sample is representative.  Random allocation balances the groups with respect to confounders.
```

We now have two sources of variability.  That is, we have two reasons the response will differ from one subject to another.  Subjects within different groups may differ because of an effect due to the group; this is the signal that we are tyring to identify with our hypotheses.  Subjects within the same group will differ due to natural variability; this is the noise we observe in the data.

Random allocation ensures the groups are balanced with respect to confounders.  However, there may still be a lot of variability within each group.  The more variability present, the more difficult it is to detect a signal.  The study will have more __power__ to detect the signal if the groups are similar.  This is the idea of having __comparative groups__.

```{definition, label=defn-power, name="Power"}
Refers to the probability that a study will find a signal when one really exists in the data generating process.  This is like saying "the probability a jury will declare a defendant guilty when they actually committed the crime."
```

```{definition, label=defn-comparative-groups, name="Comparative Groups"}
The idea that the treatment groups (levels of the factor under study) should be as similar as possible to reduce external variability in the process.
```

It is tempting to manually adjust the treatment groups to achieve what the researcher views as balance.  This temptation should be avoided as balancing one feature of the subjects may lead to an imbalance in other features.  We want to rely on randomization.  However, when there is a particular feature which we would like to balance, we can employ specialized randomization techniques.  For example, if we would like an equal number of Democrats and Republicans in a study, we can use stratified random sampling (see Definition \@ref(def:defn-stratified-random-sample)) to ensure equal representation.  During the random allocation, we can employ __blocking__, in which the random allocation to treatments happens within a secondary feature.

```{definition, label=defn-blocking, name="Blocking"}
One way of minimizing variability contributed by an inherit characteristic.  All observations that are linked through the characteristic are grouped together and random allocation occurs _within_ the block.
```

```{example, label=anovadata-golf, name="Overseeding Golf Greens"}
Golf is a major pasttime, especially in southern states.  Each winter, the putting greens need to be overseeded with grasses that will thrive in cooler weather.  This can affect how the ball rolls along the green.  @Dudeck1981 reports on an experiment that involved comparing the ball roll for greens seeded with one of five varieties of rye grass.  Ball roll was measured by the mean distance (in meters) that five balls traveled on the green.  In order to induce a constant initial velocity, each ball was rolled down an inclined plane.

Because the distance a ball rolls is influenced by the slope of the green, 20 greens were placed into four groups in such a way that the five greens in the same group had a similar slope.  Then, within each of these four groups, each of the five greens was randomly assigned to be overseeded with one of the five types of Rye grass.  The average ball roll was recorded for each of the 20 greens.
```

The data for Example \@ref(ex:anovadata-golf) is shown in Table \@ref(tab:anovadata-golf-table).

```{r anovadata-golf-data, echo=FALSE}
golf.df <- data_frame(
  Variety = rep(c("A", "B", "C", "D", "E"), times = 4),
  Slope_Group = factor(rep(c(1, 2, 3, 4), each = 5)),
  Ball_Roll = c(2.764, 2.568, 2.506, 2.612, 2.238,
                3.043, 2.977, 2.533, 2.675, 2.616,
                2.600, 2.183, 2.334, 2.164, 2.127,
                3.049, 3.028, 2.895, 2.724, 2.697)
)
```

```{r anovadata-golf-table, echo=FALSE}
golf.df %>% 
  rename(
    `Rye Grass Variety` = Variety,
    `Slope of Green Grouping` = Slope_Group,
    `Mean Distance Traveled (m)` = Ball_Roll) %>%
  knitr::kable(caption = "Data from Overseeding Golf Greens example.")
```

It would have been easy to simply assign 4 greens to each of the Rye grass varieties; the random allocation would have balanced the slope of the greens across the five varieties.  However, an additional layer was added to the design in order to control some of that additional variability.  In particular, greens with similar slopes were grouped together; then, the random allocation to Rye grass varieties happened _within_ groups of greens.  As a result, what we see is that there is one green of each type of slope for each Rye grass variety.  This has the effect of reducing variability due to nuisance characteristics of the subjects.

```{block2, type="rmdtip"}
Blocking is often a way of gaining additional power when limited resources require your study to have a small sample size.
```

An extreme case of blocking occurs when you repeatedly measure the response on the same subject under different treatment conditions.  For example, a pre-test/post-test study is an example of a study which incorporates blocking.  In this case, the blocks are the individual subjects.  The subjects then undergo each of the possible treatment options.  The rationale here is to use every subject as his or her own control.  The treatment groups are then as similar as possible.

We do note that blocking, while a powerful aspect of a design, has an impact on the type of analysis that can be conducted.  Specifically, we must account for the blocking when conducting the analysis.  We will discuss this in Chapter \@ref(ANOVAblocking).

```{r anovadata-organic-data, echo=FALSE, ref.label="caseorganic-data"}
```

How did the design of the [Organic Food Case Study](#CaseOrganic) incorporate these aspects?  First, we notice that random allocation was utilized.  Each of the `r nrow(organic.df)` participants was randomly assigned to one of three treatment groups (type of food to which the particpant was exposed).  The random allocation allows us to make causal conclusions from the data as any confounder should be balanced across the three foods.  For example, subjects who adhere to a strict diet for religious purposes would naturally tend toward organic foods and higher moral expectations.  However, for each subject like this exposed to organic foods, there is someone like this (on average) who was assigned to the comfort foods (on average).  We also note that there is replication.  Instead of assigning only one subject to each of the three treatment groups, we have several subjects within each group.  This allows us to evaluate the degree to which the results vary within a particular treatment group.

The study does not make use of blocking.  There are a couple of potential reasons for this; first, with such a large sample size, the researchers may not have thought it necessary.  Second, it could be that there was a restriction on time.  For example, researchers may have considered having students be exposed to each of the three types of food and answering different scenarios after each.  However, this would take a longer amount of time to collect data.  Third, it could be that researchers were not concerned about any identifiable characteristics that would generate additional variability.  Regardless, the study is not worse off because it did not use blocking; it is still a very reliable design.

While it is clear that random allocation was utilized in the design, random selection was not.  Students participating in the study are those from a particular lecture hall.  As a result, these students were not randomly sampled from all college students (or even from the university student body).  As a result, we must really consider whether the conclusions drawn from this study would apply to all college students within the United States.  Having additional information on their demographics may help determine this, but in general, this is not something that can be definitively answered.  It is an assumption we are either willing to make or not.  More, notice that the original question was not focused on college students; however, the sample consists only of college students.  This can impact the broader generalization of our results.  It is quite possible that we observe an effect in college students that is not present in the larger population.  We should always be careful to ensure that the sample we are using adequately represents the population.


## Collecting Observational Data
An inability to conduct a controlled experiment does not mean we neglect study design.  Random sampling is still helpful in ensuring that the data is representative of the population.  Similarly, ensuring there are a sufficient number of replications to capture the variability within the data is an important aspect of conducting an observational study.  When collecting observational data, one of the most important steps is constructing a list of potential confounders and then collecting data on these variables.  This will allow us to account for these confounders in our analysis; we cannot model what we do not collect.  
