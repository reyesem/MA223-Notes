# Comparing the Means of Two Independent Groups (Two-Sample t-Tests) {#TwoMeans}

In the previous chapter, we saw that the one-sample t-test is equivalent to a regression model with an intercept only.  In this chapter, we examine the common "two-sample t-test."


## Framing the Question
Consider the following question:

  > Does the birthweight, on average, of an infant born in North Carolina different for women who use tobacco during pregnancy compared to those who do not?
  
Let $\mu_1$ and $\mu_2$ represent the average birthweight of infants for whom their mother consumed tobacco during pregnancy and those for whom their mother did not, respectively.  Then, the hypotheses which capture this question of interest are

  > $H_0: \mu_1 = \mu_2$  
  > $H_1: \mu_1 \neq \mu_2$
  
Figure \@ref(fig:twomeans-plot) compares the birthweights for infants whose mother consumed tobacco with those whose mother did not.  The birthweight of infants tends to be lower (average of `r round(mean(subset(babies.df$Weight, babies.df$Tobacco=="Yes")))` grams vs. `r round(mean(subset(babies.df$Weight, babies.df$Tobacco=="No")))` grams).

```{r twomeans-plot, echo=FALSE, fig.cap="Examining the effect of tobacco use in pregnancy with the resulting birthweight of the child."}
set.seed(201709)
ggplot(data = babies.df,
       mapping = aes(x = Tobacco, y = Weight)) +
  geom_boxplot(size = 1.1) +
  labs(x = "Tobacco Use of Mother During Pregnancy", 
       y = "Birthweight of Infant (g)") +
  geom_jitter(height = 0, width = 0.2, alpha = 0.25) +
  theme_bw(12)
```




## Classical Approach
The classical method of addressing this question of interest is to conduct a "two-sample t-test."  This procedure defines a standardized test statistic as

$$T = \frac{\left(\bar{x}_1 - \bar{x}_2\right)}{\sqrt{s_1^2/n_1 + s_2^2/n_2}}$$

where $\bar{x}_1$ and $\bar{x}_2$ represent the sample mean for each group; $s^2_1$ and $s_2^2$ represent the sample variance for each group; and, $n_1$ and $n_2$ represent the number of observations within each group.  For our sample, we have that

$$T = \frac{`r round(mean(subset(babies.df$Weight, babies.df$Tobacco=="Yes")))` - `r round(mean(subset(babies.df$Weight, babies.df$Tobacco=="No")))`}{\sqrt{(`r round(var(subset(babies.df$Weight, babies.df$Tobacco=="Yes")))`/`r sum(babies.df$Tobacco=="Yes")`) + (`r round(var(subset(babies.df$Weight, babies.df$Tobacco=="No")))`/`r sum(babies.df$Tobacco=="No")`)}}$$

A model for the null distribution of this standardized test statistic is derived under three conditions:

  1.  The birthweight of an infant whose mother used tobacco is independent of the birthweight of any infant whose mother did not use tobacco.
  2.  The birthweights of infants within a group are independent of one another.
  3.  The birthweights of infants within a group follow a Normal distribution.
  
Under these conditions, we have an analytical model for the null distribution of the standarized test statistic.  The probability model which corresponds to the null distribution is called the "t-distribution", hence the name "two-sample t-test."  Similarly, we can obtain a sampling distribution to estimate the parameter of interest using an analytical model.

```{r twomeans-ci, echo=FALSE}
ci <- t.test(subset(babies.df$Weight, babies.df$Tobacco=="Yes"),
             subset(babies.df$Weight, babies.df$Tobacco=="No"),
             alternative = "two.sided")$conf.int
```

Figure \@ref(fig:twomeans-t-test) shows the model for the sampling distribution of the difference in the sample means and the computation of the corresponding confidence interval.  From the data, there is evidence that the average birthweight of infants whose mothers used tobacco during pregnancy is lower than that of those whose mothers do not (95% CI = (`r round(ci[1], 2)`, `r round(ci[2], 2)`), difference in grams for mothers who use tobacco and those who do not).

```{r twomeans-t-test, echo=FALSE, fig.cap="Sampling distribution of the difference in two sample means for a two-sample t-test.  The shaded region represents the 95% confidence interval."}
plot.dat <- data_frame(
  x = seq(-5, 5, length.out = 1000),
  mu = mean(subset(babies.df$Weight, babies.df$Tobacco=="Yes")) - 
    mean(subset(babies.df$Weight, babies.df$Tobacco=="No")),
  sd = sqrt(var(subset(babies.df$Weight, babies.df$Tobacco=="Yes"))/sum(babies.df$Tobacco=="Yes") +
              var(subset(babies.df$Weight, babies.df$Tobacco=="No"))/sum(babies.df$Tobacco=="No")),
  d = x*sd + mu,
  y = dt(x, df = nrow(babies.df) - 1)*(1/sd),
  group = (d<=ci[2] & d>=ci[1])
)

ggplot(data = plot.dat,
       mapping = aes(x = d, y = y, fill = group)) +
  geom_area(color = "black", size = 1.1) +
  labs(x = "Sample Mean Difference in Birthweight (Tobacco Use - No Tobacco Use)") +
  scale_fill_manual(values = c("TRUE" = "red", "FALSE" = "grey75")) +
  geom_vline(data = data_frame(xintercept = ci),
             mapping = aes(xintercept = xintercept),
             colour = "red", linetype = 2, size = 1.1) +
  annotate("label", x = ci[1], y = 0.004, label = round(ci[1], 2), colour = "red") +
  annotate("label", x = ci[2], y = 0.004, label = round(ci[2], 2), colour = "red") +
  guides(fill = "none") +
  theme_bw(12) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank())
```

## Connection to Modeling
The classical two-sample t-test is equivalent to a regression model which has a single categorical predictor with only two levels.  That is, consider the following model for the data generating process:

$$(\text{Birthweight})_i = \beta_0 + \beta_1\mathbb{I}(\text{i-th infant's mother used tobacco during pregnancy}) + \epsilon_i$$

where the following conditions are placed on the error term:

  1.  The errors in the birthweight have a mean of 0 for both infants whose mother used tobacco and those whose mother did not.
  2.  The error in the birthweight for one infant is independent of the error in the birthweight for any other infant.
  3.  The variability of the error in the birthweights is the same for both those born to mothers who used tobacco and those whose mother did not.
  4.  The errors in the birthweight follow a Normal Distribution.
  
Notice that $\beta_1$ in the above model is the average difference in the birthweight between those infants whose mother used tobacco and those infants whose mother did not.  Therefore, $\beta_1 = \mu_1 - \mu_2$.  Therefore, our above hypotheses are equivalent to

  > $H_0: \beta_1 = 0$  
  > $H_0: \beta_1 \neq 0$
  
This is a standard question in a regression analysis.  Therefore, we can estimate the parameters using least squares.  Table \@ref(tab:twomeans-fit) summarizes this fit.  Notice that $\widehat{\beta}_0$ is equivalent to $\bar{x}_2$ and $\widehat{\beta}_1 = \bar{x}_1 - \bar{x}_2$.  However, the 95% confidence interval does not agree with what we computed above.  The reason, we enforced different conditions during our analysis.

```{r twomeans-fit, echo=FALSE}
fit.babies.two <- lm(Weight ~ Tobacco, data = babies.df)

fit.babies.two %>%
  tidy() %>%
  cbind(confint_tidy(fit.babies.two)) %>%
  select(Term = term,
         Estimate = estimate,
         `Standard Error` = std.error,
         `95% LCL` = conf.low,
         `95% UCL` = conf.high,
         `P-Value` = p.value) %>%
  mutate(Term = recode(Term, 
                       "(Intercept)" = "Intercept",
                       "TobaccoYes" = "Tobacco Use")) %>%
  knitr::kable(digits = 2,
               caption = "Summary of an a model fit to explain the birthweight of babies depending on the mother's use of tobacco during pregnancy.")
```

```{r twomeans-boot, echo=FALSE}
set.seed(201709)
samp.distn <- boot_model(fit.babies.two, constant.var = FALSE) %>%
  filter(term=="TobaccoYes")
```

Remember, if two analyses differ in their results, it is because the two approaches make different assumptions.  So, what differed in our approaches.  Note that the regression approach assumed the variability in each group was similar.  The two-sample t-test did not make this assumption[^tcaveat].  However, we can relax this assumption building an empirical model for the sampling distribution.  

While the exact results do not agree, the two approaches are conceptually similar.  We also note that the p-value from the regression approach is the same as that given by the classical ANOVA model for this same problem.  Again, since the conditions are equivalent between the classical regression model and the classical ANOVA model, we should not be surprised that the results are the same.

[^tcaveat]: The version of the two-sample t-test presented here did not assume the variability in each group was the same.  There is a version of the two-sample t-test (known as the pooled two-sample t-test) which does make this assumption.  In this case, the results agree exactly with both regression and ANOVA.  Often in casual conversation, people do not say which conditions they are enforcing, making the term "two-sample t-test" ambiguous.
