# Assessing Modeling Assumptions {#Regassessment}

Thus far, we have considered a model of the form

$$(\text{Response})_i = \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor})_{j,i} + \epsilon_i$$

for the data-generating process of a quantitative response as a function of one or more predictors.  For example, for the [Seismic Activity Case Study](#CaseGreece), we considered a model that explained the bracketed duration at a location as a function of the magnitude of the earthquake and the distance the earthquake was from the location.  This model had the form

$$(\text{Bracketed Duration})_i = \beta_0 + \beta_1(\text{Magnitude})_i + \beta_2(\text{Epicentral Distance})_i + \epsilon_i$$


Estimates for the unknown parameters in this model were obtained via least squares estimation.  In order to obtain a model for the sampling distribution of these estimates, and thereby conduct inference, we added the following conditions to the distribution of the error term under the classical regression model:

  1. The error in the bracketed duration has an average of 0 regardless of the magnitude of the earthquake and the distance the location is from the epicenter of the quake.
  2. The error in the bracketed duration for one location is independent of the error in the bracketed duration for any other location.
  3. The variability of the error in the bracketed duration is the same regardless of the magnitude of the earthquake and the distance the location is from the epicenter of the quake.
  4. The errors in the bracketed duration follow a Normal distribution.
  
We were also able to develop an empirical model for the sampling distribution only enforcing the first two of these conditions on the distribution of the error.  Unfortunately, regardless of which conditions we would like to assume are consistent with th edata, we cannot simply state these conditions and hope they hold.  In order to rely on the p-values and confidence intervals produced from any modeling procedure, the data must be consistent with these conditions.

In this section, we discuss how to use residuals to assess these conditions qualitatively.


## Computing Residuals
Recall we defined a residual (Definition \@ref(def:defn-residual)) as the difference between an observed value and the estimated deterministic component of a model.  Therefore, in order to first compute a residual, we must first estimate the unknown parameters.  For a general regression model, this has the form

$$(\text{Residual})_i = (\text{Response})_i - \widehat{\beta}_0 - \sum_{j=1}^{p} \widehat{\beta}_j (\text{Predictor})_{j,i}$$

As before, we can use these residuals to qualitatively assess whether the data we have obtained is consistent with the assumptions we have made.


## Assessing Mean 0
It is tempting to read this condition and believe that a rational way to assess this assumption is determine if the average of the residuals is 0.  However, the condition is _not_ that the average error is 0; though, the difference may be subtle at first glance.  The condition is that the average error is 0 for all values of the predictors.  Therefore, in order to assess this assumption, we need to graphically assess how the average behaves over a range of predictor values.  We capture this by looking at the predicted values themselves.  Figure \@ref(fig:regassessment-mean0) shows the relationship between the residuals and the associated predicted (or fitted) values for the observations in the data set.  

```{r regassessment-diagnostics, echo=FALSE}
fit.greece.mlr.diag <- suppressWarnings(augment(fit.greece.mlr))
```

```{r regassessment-mean0, echo=FALSE, fig.cap="Plot of the residuals vs. the predicted values for a model predicting bracketed duration as a function of both the magnitude and the epicentral distance for a location."}
ggplot(data = fit.greece.mlr.diag,
       mapping = aes(x = .fitted,
                     y = .resid)) +
  geom_point() +
  geom_smooth(method = "loess") +
  geom_ribbon(data = data_frame(x = c(4, 5), 
                                ymax = c(4, 4), 
                                ymin = c(-5, -5)),
              mapping = aes(x = x, y = NULL, ymax = ymax, ymin = ymin),
              fill = "green", alpha = 0.2) +
  geom_ribbon(data = data_frame(x = c(10, 11),
                                ymax = c(20, 20),
                                ymin = c(-10, -10)),
              mapping = aes(x = x, y = NULL, ymax = ymax, ymin = ymin),
              fill = "green", alpha = 0.2) +
  labs(x = "Predicted Values", y = "Residuals") +
  theme_bw(12)
```

If the data is consistent with the condition, then as you move left to right across the plot, the residuals should tend to balance out at 0.  Imagine a window around the residuals (shown in the figure as green rectangles), and imagine moving that window from left to right.  If that window has to shift up or down to contain the cloud of residuals, that signals a problem.  The smoother has been added to the plot to help in identifying trends.  Any trends in the location of this graphic would indicate the data is not consistent with the condition.  

There is some slight evidence of curvature in this graphic, but it is not that extreme.  As a general rule of thumb, if the bands on the smoother tend to capture the 0 line, then the data is fairly consistent with the condition.  Overall, it is probably reasonable to say this dataset is consistent with these conditions.  There are no overwhelming trends in the residuals suggesting curvature is present.


## Assessing Independence
Generally, independence is assessed through the context of the data collection scheme.  By carefully considering the manner in which the data was collected, we can typically determine whether it is reasonable that the errors in the response are independent of one another.  Some key things to consider when examining the data collection process:
  - Are there repeated observations made on the same subject?  This often suggests some type of relationship between the responses and therefore would not be consistent with errors being independent.
  - Is the response measured over time (time-series) such as daily temperature over the course of a month?  Time-series data often exhibits strong period-to-period relationships suggesting the errors are not independent.  For example, if it is hot today, it will probably be hot tomorrow as well.
  - Is there a learning curve in how the data was collected?  Learning curves again suggest some dependence from one observation to the next.
  
Random sampling and random assignment allow us to confidently state that the errors are independent of one another.  One additional pitfall to watch out for when collecting your own data is whether there is some type of systematic error in the measurement device.
  - Measurement devices which are failing over time will introduce a dependence from one observation to the next.  Imagine a bathroom scale that begins to add an additional pound each day.  Then, being above average weight one day will most likely lead to an above average weight the next, due primarily to the measurement device.
  
This last point illustrates a particular deviation from our condition of independence in which two observations collected close together in time are related.  When we know the order in which the data was collected, we can assess whether the data is consistent with independence or tends to deviate in this manner.  This is done graphically through a time-series plot of the residuals.  If two errors were unrelated, then the value of one residual should tell us nothing about the value of the next residual.  Therefore, a plot of the residuals over time should look like noise (since residuals are supposed to be estimates of noise).  If there are any trends, then it suggests the data is not consistent with independence.

For the [Seismic Activity Case Study](#CaseGreece), the data was actually collected over time as the earthquakes occurred.  More, as technology has changed over time, it is reasonable to fear that the errors in our observations are related over time.  In order to assess this, consider the plot of the residuals from fitting the above model against the order in which they were collected; this is shown in Figure \@ref(fig:regassessment-independence).  Based on the figure, there is no clear trend in either the location or spread of the residuals over time.  It is reasonable to assume that the data is consistent with this condition.

```{r regassessment-independence, echo=FALSE, fig.cap="Time series plot of the residuals for a model predicting bracketed duration as a function of both the magnitude and the epicentral distance for a location."}
ggplot(data = fit.greece.mlr.diag,
       mapping = aes(x = seq_along(.rownames),
                     y = .resid)) +
  geom_line() +
  geom_point() +
  labs(x = "Order of Data Collection", y = "Residuals") +
  theme_bw(12)
```



## Assessing Homoskedasticity
Similar to assessing whether the data is consistent with the condition of the errors being 0 on average for all values of the predictors, homoskedasticity suggests the variability in the errors is consistent for all values of the predictors.  Therefore, we rely on the same graphical assessment: Figure \@ref(fig:regconditions-mean0).  However, instead of focusing on a trend in the location of the residuals, we are focused on a trend in the variability.  Again, imagine a window (illustrated as green rectangles) around the residuals.  As you move left to right, if the size of the window has to change in order to keep the residuals inside, then that is an indication that the variability is changing.  There is a clear "fan shape" to the residuals as you move left to right.  This suggests that the precision of the model decreases when making larger predictions.  This goes back to something we observed in Chapter \@ref(Regsummaries) when examining a plot of the raw data.  Figure \@ref(fig:regsummaries-magnitude) illustrates that for large earthquakes (high magnitudes), the bracketed duration was much more variable than for smaller earthquakes.  So, our model is not as precise in some regions.

This explains why the analytical models of the sampling distribution did not match the empirical models in Figure \@ref(fig:regconditions-mlr-bootstrap-plot).  Since there is clear evidence that the data is not consistent with the condition that the variability of the errors is constant for all levels of the predictors, then it is not safe to assume the classical regression model.  That is, the confidence intervals and p-values, as well as the underlying model for the sampling distribution that generated them, constructed assuming the data is consistent with all four conditions are suspect.  As a result, we can obtain an improved model for the sampling distribution by reducing the number of conditions we place on the stochastic portion of the model.


## Assessing Normality
We again emphasize the use of a probability plot to assess whether the residuals behave as a sample from a Normal distribution.  If the data is consistent with this condition, then we would expect that the probability plot of the residuals would reveal a linear relationship.  Trends away from a linear relationship suggest the proposed Normal distribution is not a reasonable model for the distribution of the errors.

Figure \@ref(fig:regassessment-normal) shows the probability plot for the residuals for the model fit above.

```{r regassessment-normal, echo=FALSE, fig.cap="Probability plot of the residuals for a model predicting bracketed duration as a function of both the magnitude and the epicentral distance for a location."}
ggplot(data = fit.greece.mlr.diag,
       mapping = aes(sample = .resid)) +
  stat_qq() +
  labs(x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_bw(12)
```

There is some evidence that the residuals are moving away from a linear relationship.  There is some curvature, particularly toward the top right portion of the graphic.  The analytic models for the sampling distribution are generally fairly robust to this condition.  That is, those models for the sampling distribution, as well as the confidence intervals and p-values they produce, tend to be accurate even if the data is not consistent with this condition.  This is especially true in large samples.  However, we can always relax this condition by building an empirical model for the sampling distribution.  Overall, this graphic does not produce a lot to be concerned about; however, given we have already established the data is not consistent with the condition of homoskedasticity, we should use an emprical model of the sampling distribution to perform inference.


## General Tips for Assessing Assumptions
As we did earlier in the text, we emphasize that the methods presented here are qualitative assessements, which means they are subjective.  That is okay.  As the analyst, it is up to you to determine which assumptions you are willing to make.  You need to determine whether you feel the data is consistent with the assumptions.  Here are two overall things to keep in mind.

First, do not spend too much time examining residual plots.  If you stare at a plot too long, you can convince yourself there is pattern in anything.  We are looking for glaring evidence that the data is not consistent with the conditions we have imposed on our model.  This is especially true when we have only a few observations.  In these settings, reading plots can be very difficult.  Again, it is about what you are comfortable assuming; how much faith do you want to place in the results?

Second, we have chosen the language carefully throughout this chapter.  We have never once stated that a condition was satisfied.  When we perform an analysis, we are making an assumption that the conditions are satisfied.  We can never prove that they are; we can only show that the data is consistent with a particular condition.  We can, however, provide evidence that a condition is violated.  When that is the case, we should be wary of trusting the resulting p-values and confidence intervals.  This is not unlike hypothesis testing; just as we can never prove the null hypothesis is true, we cannot prove that a condition is satisfied.

Finally, any conditions required for a particular analysis should be assessed.  If your sample is not consistent with the necessary conditions, you should choose a different analysis.  The inference you obtain from an analysis is only reliable of the data is consistent with any necessary conditions.
