# Assessing Modeling Assumptions {#ANOVAassessment}

In the previous chapter, we introduced a model for how a quantitative response being generated across multiple groups.  For the [Organic Food Case Study](#CaseOrganic), this is essentially
$$
\text{(Moral Expectation Score)}_i = \sum_{j=1}^3 \mu_j \mathbb{I}(\text{i-th subject in food exposure group j}) + \epsilon_i
$$

Further, we added two conditions to the distribution of the error term:
  1. The error in the moral expectation score for one individual is independent of the error in the moral expectation score for all other individuals.
  2. The variability in the error for the moral expectation score within a group is similar for any food exposure group.
  
Unfortunately, we cannot just state that these are the conditions we hope hold for the data generating process and move on our merry way.  Since the p-value was computed assuming these conditions hold, the p-value is only meaningful if the data is consistent with these conditions.  If any of these conditions is violated, then the p-value is meaningless.

```{block2, type="rmdkeyidea"}
Residuals, since they are estimates of the noise in the data-generating process, provide a way of assessing the modeling conditions placed on the distribution of the error term.
```

In this section, we discuss how to use residuals to assess these conditions qualitatively.


## Assessing Independence
Generally, independence is assessed through the context of the data collection scheme.  By carefully considering the manner in which the data was collected, we can typically determine whether it is reasonable that the errors in the response are independent of one another.  Some key things to consider when examining the data collection process:
  - Are there repeated observations made on the same subject?  This often suggests some type of relationship between the responses and therefore would not be consistent with errors being independent.
  - Is the response measured over time (time-series) such as daily temperature over the course of a month?  Time-series data often exhibits strong period-to-period relationships suggesting the errors are not independent.  For example, if it is hot today, it will probably be hot tomorrow as well.
  - Is there a learning curve in how the data was collected?  Learning curves again suggest some dependence from one observation to the next.
  
Random sampling and random assignment allow us to confidently state that the errors are independent of one another.  One additional pitfall to watch out for when collecting your own data is whether there is some type of systematic error in the measurement device.
  - Measurement devices which are failing over time will introduce a dependence from one observation to the next.  Imagine a bathroom scale that begins to add an additional pound each day.  Then, being above average weight one day will most likely lead to an above average weight the next, due primarily to the measurement device.
  
This last point illustrates a particular deviation from our condition of independence in which two observations collected close together in time are related.  When we know the order in which the data was collected, we can assess whether the data is consistent with independence or tends to deviate in this manner.  This is done graphically through a __time-series plot__ of the _residuals_.  If two errors were unrelated, then the value of one residual should tell us nothing about the value of the next residual.  Therefore, a plot of the residuals over time should look like noise (since residuals are supposed to be estimates of noise).  If there are any trends, then it suggests the data is not consistent with independence.

```{definition, label=defn-time-series-plot, name="Time Series Plot"}
Plot of a variable over time.  This plot allows us to assess some deviations from independence.  A trend in the location or spread of the points over time suggests a deviation from independence.
```

As an example, consider the time-series plots shown in Figure \@ref(fig:anovaassessment-independence-violations), both representing hypothetical datasets.  In Panel A, the residuals display a trend in the location over time.  Knowing that a response was below average suggests the next response will also be below average.  In Panel B, the results deplay a trend in the spread over time.  This suggests that measurements taken later in the study were less precise.  Both panels are then examples of patterns which would suggest the data is not consistent with the condition of independence.

```{r anovaassessment-independence-violations, echo=FALSE, fig.cap="Examples of trends in a time-series plot of the residuals.  Such trends indicate the data is not consistent with the condition that the errors are independent of one another."}
set.seed(201708)

plot.dat <- data_frame(
  Panel = rep(c("Panel A", "Panel B"), each = 100),
  Response = c(rnorm(100, mean = seq(3, -3, length.out = 100), sd = 1),
               rnorm(100, mean = 0, sd = seq(0.5, 3, length.out = 100))),
  Order = rep(seq(100), times = 2)
)

ggplot(data = plot.dat,
       mapping = aes(x = Order, y = Response)) +
  geom_line() +
  geom_point() +
  labs(x = "Order of Data Collection", y = "Residual") +
  theme_bw(12) +
  facet_wrap(~Panel)
```

Instead, if the data were consistent with the condition of independence on the error terms, we would expect to see a plot as in Figure \@ref(fig:anovaassessment-independence-reasonable).  Notice there are no trends in the location or spread of the residuals.

```{r anovaassessment-independence-reasonable, echo=FALSE, fig.cap="Example of a time-series plot of residuals which shows no trends in location or spread.  This is consistent with what we would expect if the condition of independence among errors were satisfied."}
set.seed(201708)

plot.dat <- data_frame(
  Order = seq(100),
  Response = rnorm(100)
)

ggplot(data = plot.dat,
       mapping = aes(x = Order, y = Response)) +
  geom_line() +
  geom_point() +
  labs(x = "Order of Data Collection", y = "Residual") +
  theme_bw(12)
```

For the [Organic Food Case Study](#CaseOrganic), participants were assessed simultaneously within a large lecture.  Therefore, there is no ordering in time to be concerned about.  Further, since students worked individually on the questionnaire, it is reasonable to assume that the errors in the moral expectation score are unrelated to one another.  


## Assessing Homoskedasticity
We want the variability in the errors within a group to be the same across the groups.  This corresponds to the spread of the response within each group is the same.  This implication leads to a simple way of assessing this assumption.  Examining the side-by-side boxplots (or jitter plots, etc.) of the response allows us to get a sense of the variability within each group.  Figure \@ref(fig:anovaassessment-variance-organic) shows the moral expectation score for each individual across the various groups.  Notice that the boxes for each group are roughly the same size; that is, the interquartile ranges are similar.  This suggests that the variability within each group is similar from one group to the next.  That is, the data is consistent with this condition.

```{r anovaassessment-variance-organic, ref.label="anovamodel-organic-boxplot", echo=FALSE, fig.cap="Comparison of the moral expectations for college students exposed to different types of food."}
```


## Assessing Normality
Assessing whether observations adhere to a particular distribution is a large area in statistical research.  Many methods have been developed for this purpose.  We emphasize a single graphical summary known as a __probability plot__.  The construction of the plot is beyond the scope of this text, but the concepts underlying its construction actually tie in nicely to the big themes of the course.  Recall that if a sample is representative, then it should be a snapshot of the underlying population.  Therefore, if we believe the underlying population has some particular distribution, we would expect the properties of this distribution to be apparent in the sample as well.

If we believe the errors follow a Normal distribution, then it is reasonable that the residuals should maintain some of those properties.  For example, the 10-th percentile of the residuals should roughly equate to the 10-th percentile expected from a Normal distribution.  Mapping up the percentiles that we observe to those that we expect is the essence of a probability plot.

```{definition, label=defn-probability-plot, name="Probability Plot"}
Graphic for comparing a theoretical probability model for the distribution an underlying population with the distribution of the sample.  Sample points should follow a straight line.  If points deviate from this linear trend, that suggests the points do not align with the proposed model.
```

While a probability plot can be used for a host of probability distributions, the most common is the normal probability plot.  Since we expect the percentiles to line up directly, we would expect a one-to-one linear relationship to be exhibited in the plot.  Trends away from a linear relationship suggest the proposed Normal distribution is not a reasonable model for the distribution of the errors.

Figure \@ref(fig:anovaassessment-normal-organic) shows the probability plot for the residuals from the [Organic Food Case Study](#CaseOrganic).

```{r anovaassessment-normal-organic, echo=FALSE, fig.cap="Probability plot of the residuals for the Organic Food Case Study.  If the errors follow a Normal distribution, we would expect the residuals to fall along a straight line."}
fit <- lm(moral_avg ~ Food_Condition, data = organic.df)
fit.aug <- suppressWarnings(augment(fit))

ggplot(data = fit.aug,
       mapping = aes(sample = .resid)) +
  stat_qq() +
  labs(x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_bw(12)
```

Overall, the points do tend to follow a straight line.  There are some deviations from a linear relationship at each end of the plot, but the deviations are not extreme.  We argue that these residuals are consistent with the errors having a Normal distribution.

For comparison, Figure \@ref(fig:anovaassessment-normal-bad) illustrates a hypothetical dataset for which the residuals suggest the condition of the errors following a Normal distribution is violated.

```{r anovaassessment-normal-bad, echo=FALSE, fig.cap="Probability plot of residuals for a hypothetical dataset.  The trend away from a straight line suggests assuming the errors follow a Normal distribution would be unreasonable."}
set.seed(201708)

plot.dat <- data_frame(
  resids = rexp(100)
)

ggplot(data = plot.dat,
       mapping = aes(sample = resids)) +
  stat_qq() +
  labs(x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_bw(12)
```


## General Tips for Assessing Assumptions
Each of the methods presented here are qualitative assessements, which means they are subjective.  That is okay.  As the analyst, it is up to you to determine which assumptions you are willing to make.  You need to determine whether you feel the data is consistent with the assumptions.  Here are two overall things to keep in mind.

First, do not spend too much time examining residual plots.  If you stare at a plot too long, you can convince yourself there is pattern in anything.  We are looking for glaring evidence that the data is not consistent with the conditions we have imposed on our model.  This is especially true when we have only a few observations.  In these settings, reading plots can be very difficult.  Again, it is about what you are comfortable assuming; how much faith do you want to place in the results?

Second, we have chosen the language carefully throughout this chapter.  We have never once stated that a condition was satisfied.  When we perform an analysis, we are making an assumption that the conditions are satisfied.  We can never prove that they are; we can only show that the data is consistent with a particular condition.  We can, however, provide evidence that a condition is violated.  When that is the case, we should be wary of trusting the resulting p-values and confidence intervals.  This is not unlike hypothesis testing; just as we can never prove the null hypothesis is true, we cannot prove that a condition is satisfied.

Finally, any conditions required for a particular analysis should be assessed.  If your sample is not consistent with the necessary conditions, you should choose a different analysis.  The inference you obtain from an analysis is only reliable of the data is consistent with any necessary conditions.

```{block2, type="rmdtip"}
The conditions for a model are placed on the error, but the residuals are used to assess whether a dataset is consistent with these conditions, allowing us to determine if assuming the conditions are satisfied is reasonable.

  1. We can never prove a condition is satisfied.
  2. The assumptions are not on the residuals, but the errors.
  3. A sample should be consistent with any conditions you impose on your model.
  
If a sample is not consistent with the conditions you impose, you should consider revising your analysis.
```
